{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Machine Learning Project - Launch\n",
    "----------------------------------------------------------------\n",
    "\n",
    "__Description:__ Use California census data to build a model of housing prices in the state. This data includes metrics such as the population, median income, and median housing price for each block group in California. Block groups (districts) are the smallest geographical unit for which the US Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people). \n",
    "\n",
    "__Goal:__ Your model should learn from this data and be able to predict the median housing price in any district, given all the other metrics.\n",
    "\n",
    "\n",
    "_This is the second part of the Jupyter Notebook page._ \n",
    "\n",
    "__Detailed Get the Data and EXplore the Data steps are in another Jupyter Notebook__\n",
    "\n",
    "\n",
    "## Get the Data\n",
    "The following _fetch_housing_data()_ creates a datasets/housing directory in your workspace, downloads the housing.tgz file, and extracts the housing.csv file from it in this directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import urllib.request as urllibrequest\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllibrequest.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"], \n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf], \n",
    "                               labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to do stratified sampling based on the income category. For this you can use Scikit-Learn’s class: StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.350533\n",
       "2    0.318798\n",
       "4    0.176357\n",
       "5    0.114583\n",
       "1    0.039729\n",
       "Name: income_cat, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should remove the income_cat attribute so the data is back to its original\n",
    "state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "_Exploring the Data Steps are in another Jupyter Notebook_ page.\n",
    "\n",
    "\n",
    "# Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a clean training set (by copying strat_train_set once again)\n",
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "# drop() creates a copy of the data and does not affect strat_train_set\n",
    "\n",
    "# separate the predictors and the labels\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Lets take care of the missing features:\n",
    "\n",
    "We saw earlier that the __total_bedrooms__ attribute has some missing values, so let’s fix this. You have three options:\n",
    "1. Get rid of the corresponding districts.\n",
    "2. Get rid of the whole attribute.\n",
    "3. Set the values to some value (zero, the mean, the median, etc.).\n",
    "\n",
    "You can accomplish these easily using DataFrame’s dropna(), drop(), and fillna() methods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# housing.dropna(subset=[\"total_bedrooms\"]) # option 1\n",
    "# housing.drop(\"total_bedrooms\", axis=1) # option 2\n",
    "# median = housing[\"total_bedrooms\"].median() # option 3\n",
    "# housing[\"total_bedrooms\"].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn provides a handy class to take care of missing values: SimpleImputer. the median can only be computed on numerical attributes, you need to create a copy of the data without the text attribute ocean_proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='median')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The has simply computed the median of each attribute and stored the result imputer in its instance variable. statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n",
       "        408.    ,    3.5409])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.51  ,   34.26  ,   29.    , 2119.5   ,  433.    , 1164.    ,\n",
       "        408.    ,    3.5409])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_num.median().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use this “trained” to transform the training set by replacing imputer missing values with the learned medians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a plain NumPy array containing the transformed features. If you want to put it back into a pandas DataFrame, it’s simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Text and Categorical Attributes\n",
    "\n",
    "Most Machine Learning algorithms prefer to work with numbers, so let’s convert these categories from text to numbers. For this, we can use Scikit-Learn’s class OrdinalEncoder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19480</th>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13685</th>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ocean_proximity\n",
       "17606       <1H OCEAN\n",
       "18632       <1H OCEAN\n",
       "14650      NEAR OCEAN\n",
       "3230           INLAND\n",
       "3555        <1H OCEAN\n",
       "19480          INLAND\n",
       "8879        <1H OCEAN\n",
       "13685          INLAND\n",
       "4937        <1H OCEAN\n",
       "4861        <1H OCEAN"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the list of categories using the instance variable categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue with this representation is that ML algorithms will assume that two nearby values are more similar than two distant values. This may be fine in some cases (e.g., for ordered categories such as “bad,” “average,” “good,” and “excellent”), but it is obviously not the case for the column (for example, categories 0 and 4 ocean_proximity are clearly more similar than categories 0 and 1). \n",
    "\n",
    "To fix this issue, a common solution is to create one binary attribute per category: one attribute equal to 1 when the category is “<1H OCEAN” (and 0 otherwise), another attribute equal to 1 when the ca gory is “INLAND” (and 0 otherwise), and so on. This is called one-hot encoding,because only one attribute will be equal to 1 (hot), while the others will be 0 (cold). The new attributes are sometimes called __dummy attributes__. Scikit-Learn provides a __OneHotEncoder__ class to convert categorical values into one-hot vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output is a SciPy sparse matrix, instead of a NumPy array. This is very useful when you have categorical attributes with thousands of categories. After onehot encoding, we get a matrix with thousands of columns, and the matrix is full of 0s except for a single 1 per row. Using up tons of memory mostly to store zeros would be very wasteful, so instead a sparse matrix only stores the location of the nonzero elements.\n",
    "\n",
    "To convert it to a (dense) NumPy array, just call the toarray() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, you can get the list of categories using the encoder’s categories_ instance variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a categorical attribute has a large number of possible categories (e.g., country code, profession, species), then one-hot encoding will result in a large number of input features.\n",
    "\n",
    "\n",
    "This may slow down training and degrade performance. If this happens, you may want to replace the categorical input with useful numerical features related to the categories: for example, you could replace the feature with the distance to the ocean (similarly, ocean_proximity a country code could be replaced with the country’s population and GDP per capita).\n",
    "\n",
    "\n",
    "Alternatively, you could replace each category with a learnable, low-dimensional vector called an embedding. Each category’s representation would be learned during training. This is an example of representation learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers\n",
    "\n",
    "If you need to write your own for tasks such as custom cleanup operations or combining specific attributes, you can implement fit() (returning self), transform(), and fit_transform() functions so that your transformer works wit Scikit-Learn without issues. \n",
    "\n",
    "If you add TransformerMixin as a base class you get the fit_transform() method. If you add BaseEstimator as a base class (and avoid *args * * kargs in the constructor), you will also get two extra methods (get_params() and set_params()) that will be useful for automatic hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# column index\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room: # if set to true, we add bedrooms_per_room\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17606</th>\n",
       "      <td>-121.89</td>\n",
       "      <td>37.29</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>2.7042</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>4.625369</td>\n",
       "      <td>2.094395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18632</th>\n",
       "      <td>-121.93</td>\n",
       "      <td>37.05</td>\n",
       "      <td>14.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.4214</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>6.00885</td>\n",
       "      <td>2.707965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14650</th>\n",
       "      <td>-117.2</td>\n",
       "      <td>32.77</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>2.8621</td>\n",
       "      <td>NEAR OCEAN</td>\n",
       "      <td>4.225108</td>\n",
       "      <td>2.025974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>-119.61</td>\n",
       "      <td>36.31</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1.8839</td>\n",
       "      <td>INLAND</td>\n",
       "      <td>5.232295</td>\n",
       "      <td>4.135977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>-118.59</td>\n",
       "      <td>34.23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6592.0</td>\n",
       "      <td>1525.0</td>\n",
       "      <td>4459.0</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>3.0347</td>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "      <td>4.50581</td>\n",
       "      <td>3.047847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      longitude latitude housing_median_age total_rooms total_bedrooms  \\\n",
       "17606   -121.89    37.29               38.0      1568.0          351.0   \n",
       "18632   -121.93    37.05               14.0       679.0          108.0   \n",
       "14650    -117.2    32.77               31.0      1952.0          471.0   \n",
       "3230    -119.61    36.31               25.0      1847.0          371.0   \n",
       "3555    -118.59    34.23               17.0      6592.0         1525.0   \n",
       "\n",
       "      population households median_income ocean_proximity rooms_per_household  \\\n",
       "17606      710.0      339.0        2.7042       <1H OCEAN            4.625369   \n",
       "18632      306.0      113.0        6.4214       <1H OCEAN             6.00885   \n",
       "14650      936.0      462.0        2.8621      NEAR OCEAN            4.225108   \n",
       "3230      1460.0      353.0        1.8839          INLAND            5.232295   \n",
       "3555      4459.0     1463.0        3.0347       <1H OCEAN             4.50581   \n",
       "\n",
       "      population_per_household  \n",
       "17606                 2.094395  \n",
       "18632                 2.707965  \n",
       "14650                 2.025974  \n",
       "3230                  4.135977  \n",
       "3555                  3.047847  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_extra_attribs = pd.DataFrame(\n",
    "    housing_extra_attribs,\n",
    "    columns=list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"],\n",
    "    index=housing.index)\n",
    "housing_extra_attribs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales. This is the case for the housing data: the total number of rooms ranges from about 6 to 39,320, while the median incomes only range from 0 to 15. We will use Scikit-Learn's transformer called StandardScaler for standardization.\n",
    "\n",
    "## Transformation Pipelines\n",
    "Scikit-Learn provides the class to help with pipeline such sequences of transformations. Here is a small pipeline for the numerical attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be more convenient to have a single transformer able to handle all columns (categorical and numerical), applying the appropriate transformations to each column. Scikit-Learn has the ColumnTransformer for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs),\n",
    "                                   (\"cat\", OneHotEncoder(), cat_attribs),])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor requires a list of tuples, where each tuple contains a name (\"num\"), a transformer (num_pipeline), and a list of names (or indices) of columns (num_attribs) that the transformer should be applied to. The transformers must return the same number of rows.\n",
    "\n",
    "Transformers applies the transformation to all attributes. Instead of using a transformer, you can specify the string \"drop\" if you want the columns to be dropped, or you can specify \"pass through\" if you want the columns to be left untouched. By default, the remaining columns (i.e., the ones that were not listed) will be dropped, but you can set the remainder hyperparameter to any transformer (or to \"passthrough\") if you want these columns to be handled differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select and train a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [210644.60459286 317768.80697211 210956.43331178  59218.98886849\n",
      " 189747.55849879]\n"
     ]
    }
   ],
   "source": [
    "# let's try the full preprocessing pipeline on a few training instances\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compare against the actual values, we see that the predictions are not exactly accurate (e.g., the first prediction is off by close to 40%!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us measure this regression model’s RMSE on the whole training set using Scikit-Learn’s mean_squared_error() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68628.19819848923"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the mean absolute error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49439.89599001897"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(housing_labels, housing_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction error is not very good. This is an example of a model underfitting the training data. When this happens it can mean that the features do not provide enough information to make good predictions, or that the model is not powerful enough. \n",
    "\n",
    "The main ways to fix __underfitting__ are:\n",
    "\n",
    "1) to select a more powerful model, \n",
    "\n",
    "2) to feed the training algorithm with better features, \n",
    "\n",
    "3) to reduce the constraints on the model.\n",
    "\n",
    "\n",
    "First let’s try a more complex model to see how it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could this model really be absolutely perfect? It is much more likely that the model has __overfit__ the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Using Cross-Validation\n",
    "\n",
    "Cross-validation comes at the cost of training the model several times, so it is not always possible.\n",
    "\n",
    "To evaluate the Decision Tree model, we can use the __train_test_split()__ function to split the training set into a smaller training set and a validation set, then train your models against the smaller training set and evaluate them against the validation set.\n",
    "\n",
    "Better alternative is to use __Scikit-Learn’s K-fold cross-validation__ feature. \n",
    "\n",
    "The following code __randomly splits the training set__ into 10 distinct subsets called __folds__, then it trains and evaluates the Decision Tree model 10 times, picking a different fold for evaluation every time and training on the other 9 folds. The result is an array containing the 10 evaluation scores:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels, \n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn’s cross-validation features expect a __utility function__ (greater is better) rather than a __cost function__ (lower is better), so\n",
    "the scoring function is actually the opposite of the MSE (i.e., a negative value), which is why the preceding code computes -scores before calculating the square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [70194.33680785 66855.16363941 72432.58244769 70758.73896782\n",
      " 71115.88230639 75585.14172901 70262.86139133 70273.6325285\n",
      " 75366.87952553 71231.65726027]\n",
      "Mean: 71407.68766037929\n",
      "Standard deviation: 2439.4345041191004\n"
     ]
    }
   ],
   "source": [
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the decision tree looks worse than linear regression. \n",
    "The Decision Tree has a score of approximately 71,407, generally ±2,439. You would not have this information if you just used one validation set. \n",
    "\n",
    "When we compute the same scores for the Linear Regression model, we see that Decision Tree model is overfitting so badly that it performs worse than the Linear Regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [66782.73843989 66960.118071   70347.95244419 74739.57052552\n",
      " 68031.13388938 71193.84183426 64969.63056405 68281.61137997\n",
      " 71552.91566558 67665.10082067]\n",
      "Mean: 69052.46136345084\n",
      "Standard deviation: 2731.6740017983457\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "    scoring=\"neg_mean_squared_error\", cv=10)\n",
    "# To check possible values for 'scoring', check https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "# All scorer objects follow the convention that higher return values are better than lower return values. \n",
    "# Thus metrics which measure the distance between the model and the data, like metrics.mean_squared_error, \n",
    "# are available as neg_mean_squared_error which return the negated value of the metric.\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try one more model: Random Forest\n",
    "__Random Forests__ work by training many Decision Trees on random subsets of the features, then averaging out their predictions. \n",
    "\n",
    "Building a model on top of many other models is called __Ensemble Learning__, and it is often a great way to push ML algorithms even further. Random forest is a type of ensembel learning.\n",
    "\n",
    "You will notice that the below code takes more time to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18603.515021376355"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [49519.80364233 47461.9115823  50029.02762854 52325.28068953\n",
      " 49308.39426421 53446.37892622 48634.8036574  47585.73832311\n",
      " 53490.10699751 50021.5852922 ]\n",
      "Mean: 50182.303100336096\n",
      "Standard deviation: 2097.0810550985693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests look very promising. However, note that the score on the training set is still much lower than on the validation sets, meaning that the model is still overfitting the training set.\n",
    "\n",
    "You __should try out many other models from various categories__ of Machine Learning algorithms (e.g., several Support Vector Machines with different kernels, and possibly a neural network),\n",
    "without spending too much time tweaking the hyperparameters. The goal is to shortlist a few (two to five) promising models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune Your Model\n",
    "\n",
    "We need to find the best possible hyperparameters. Instead of trying the hyperparameters manually (which would be tedious and time consuming). We can utilize Scikit-Learn’s GridSearchCV function: \n",
    "\n",
    "\n",
    "## Grid Search\n",
    "\n",
    "We tell the GridSearchCV function which hyperparameters we want it to experiment with and what values to try out, and it will use cross-validation to evaluate all the possible combinations of hyperparameter values.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "For example, the following code searches for the best combination of hyperparameter values for the RandomForestRegressor:\n",
    "You can check the parameters for the RandomForestRegressor here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, \n",
    "              {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This param_grid tells Scikit-Learn to first evaluate all 3 × 4 = 12 combinations of n_estimators and max_features hyperparameter values specified in the first dict, then try all 2 × 3 = 6 combinations of hyperparameter values in the second dict, but this time with the bootstrap hyperparameter set to False instead of True (which is the default value for this hyperparameter).\n",
    "\n",
    "\n",
    "The grid search will explore 12 + 6 = 18 combinations of RandomForestRegressor hyperparameter values, and it will train each model 5 times (since we are using five fold cross validation, cv=5). There will be 18 × 5 = 90 rounds of training! It may take quite a long time. \n",
    "\n",
    "When it is done you can get the best combination of parameters like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 30}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=6, n_estimators=30)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to printout the evaluation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64439.26466583013 {'max_features': 2, 'n_estimators': 3}\n",
      "55794.47999698332 {'max_features': 2, 'n_estimators': 10}\n",
      "52768.52918326962 {'max_features': 2, 'n_estimators': 30}\n",
      "59867.56064836987 {'max_features': 4, 'n_estimators': 3}\n",
      "52850.62332714188 {'max_features': 4, 'n_estimators': 10}\n",
      "50721.49838834493 {'max_features': 4, 'n_estimators': 30}\n",
      "59545.20614938541 {'max_features': 6, 'n_estimators': 3}\n",
      "52219.67703566205 {'max_features': 6, 'n_estimators': 10}\n",
      "49952.500767214544 {'max_features': 6, 'n_estimators': 30}\n",
      "59095.18195374801 {'max_features': 8, 'n_estimators': 3}\n",
      "52544.48821806916 {'max_features': 8, 'n_estimators': 10}\n",
      "50019.67708813174 {'max_features': 8, 'n_estimators': 30}\n",
      "63150.381991503 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "54351.713757541904 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "60720.04081137159 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "53068.639672281046 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "58210.90771064935 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51861.66766879647 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping the Best:\n",
    "If GridSearchCV is initialized with __refit=True__ (which is the _default_), then once it finds the best estimator using crossvalidation, it retrains (refits) it on the whole training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation as Hyperparameters\n",
    "\n",
    "Don’t forget that you can treat some of the data preparation steps as hyperparameters. For example, the grid search will automatically find out whether or not to add a feature you were not sure about (e.g., using the add_bedrooms_per_room hyperparameter of your CombinedAttributesAdder transformer). It may similarly be used to automatically find the best way to handle outliers, missing features, feature selection, and more.\n",
    "\n",
    "## Randomized Search\n",
    "When the hyperparameter search space is large, it is often preferable to use RandomizedSearchCV instead.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html?highlight=randomizedsearchcv\n",
    "\n",
    "This class can be used in much the same way as the GridSearchCV class, but instead of trying out all possible combinations, it evaluates a given number of random combinations by selecting a random value for each hyperparameter at every iteration. This approach has two main benefits:\n",
    "- If you let the randomized search run for, say, 1,000 iterations, this approach will explore 1,000 different values for each hyperparameter (instead of just a few values per hyperparameter with the grid search approach).\n",
    "- Simply by setting the number of iterations, you have more control over the computing budget you want to allocate to hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fd6f093d520>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fd7605e29a0>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49150.70756927707 {'max_features': 7, 'n_estimators': 180}\n",
      "51389.889203389284 {'max_features': 5, 'n_estimators': 15}\n",
      "50796.155224308866 {'max_features': 3, 'n_estimators': 72}\n",
      "50835.13360315349 {'max_features': 5, 'n_estimators': 21}\n",
      "49280.9449827171 {'max_features': 7, 'n_estimators': 122}\n",
      "50774.90662363929 {'max_features': 3, 'n_estimators': 75}\n",
      "50682.78888164288 {'max_features': 3, 'n_estimators': 88}\n",
      "49608.99608105296 {'max_features': 5, 'n_estimators': 100}\n",
      "50473.61930350219 {'max_features': 3, 'n_estimators': 150}\n",
      "64429.84143294435 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.24699052e-02, 6.38080322e-02, 4.27504395e-02, 1.65343807e-02,\n",
       "       1.56100762e-02, 1.60929106e-02, 1.52149598e-02, 3.45178404e-01,\n",
       "       5.74445360e-02, 1.08468449e-01, 7.05907498e-02, 8.77441303e-03,\n",
       "       1.60563229e-01, 6.10403994e-05, 3.08961266e-03, 3.34886200e-03])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_rnd = rnd_search.best_estimator_.feature_importances_\n",
    "feature_importances_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3451784043801197, 'median_income'),\n",
       " (0.1605632289158767, 'INLAND'),\n",
       " (0.10846844860879654, 'pop_per_hhold'),\n",
       " (0.07246990515559049, 'longitude'),\n",
       " (0.07059074984842853, 'bedrooms_per_room'),\n",
       " (0.06380803224443841, 'latitude'),\n",
       " (0.057444535971841064, 'rooms_per_hhold'),\n",
       " (0.04275043945662488, 'housing_median_age'),\n",
       " (0.01653438073955306, 'total_rooms'),\n",
       " (0.016092910597195798, 'population'),\n",
       " (0.015610076150868492, 'total_bedrooms'),\n",
       " (0.015214959838627942, 'households'),\n",
       " (0.008774413032023276, '<1H OCEAN'),\n",
       " (0.003348861998751043, 'NEAR OCEAN'),\n",
       " (0.0030896126618977565, 'NEAR BAY'),\n",
       " (6.104039936629334e-05, 'ISLAND')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "#cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"] # old solution\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances_rnd, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization\n",
    "Bayesian Optimization is an approach that uses Bayes Theorem to direct the search in order to find the minimum or maximum of an objective function.\n",
    "\n",
    "It is an approach that is most useful for objective functions that are complex, noisy, and/or expensive to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 3.4 MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting pyaml>=16.9\n",
      "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages (from scikit-optimize) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages (from scikit-optimize) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages (from scikit-optimize) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages (from scikit-optimize) (1.20.3)\n",
      "Requirement already satisfied: PyYAML in /Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skopt 0.9.0\n"
     ]
    }
   ],
   "source": [
    "# report scikit-optimize version number\n",
    "import skopt\n",
    "print('skopt %s' % skopt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once installed, the Scikit-Optimize library provides a similar interface for performing a Bayesian Optimization of model hyperparameters via the _BayesSearchCV_ class.\n",
    "\n",
    "This class can be used in the same way as the Scikit-Learn equivalents.\n",
    "\n",
    "First, the search space must be defined as a dictionary with hyperparameter names used as the key and the scope of the variable as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, \n",
    "              {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},]\n",
    "\n",
    "# define search space\n",
    "#params = dict()\n",
    "#params['n_estimators'] = (3, 10)\n",
    "#params['max_features'] = (2, 3, 4)\n",
    "#params['bootstrap'] = (False)\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "/Users/otopsakal/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8158593509179421\n",
      "OrderedDict([('max_features', 8), ('n_estimators', 30)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=42)\n",
    "# define the search\n",
    "bayes_search = BayesSearchCV(estimator=forest_reg, search_spaces=param_grid, n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "bayes_search.fit(housing_prepared, housing_labels)\n",
    "# report the best result\n",
    "print(bayes_search.best_score_)\n",
    "print(bayes_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods\n",
    "The group (or “ensemble”) will often perform better than the best individual model (just like Random Forests perform better than the individual Decision Trees they rely on), especially if the individual models make very different types of errors.\n",
    "\n",
    "## Analyze the Best Models and Their Errors\n",
    "\n",
    "You will often gain good insights on the problem by inspecting the best models. For example, the can indicate the relative importance of each RandomForestRegressor attribute for making accurate predictions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.04662152e-02, 6.75178072e-02, 4.28560867e-02, 1.67290185e-02,\n",
       "       1.58233223e-02, 1.68539712e-02, 1.59026979e-02, 3.14270731e-01,\n",
       "       7.06684525e-02, 1.08294535e-01, 7.01217202e-02, 1.62172461e-02,\n",
       "       1.54640130e-01, 9.31454460e-05, 3.01812003e-03, 6.52680091e-03])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_grid = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you display these importance scores next to their corresponding attribute names, you may want to try dropping some of the less useful features (e.g., apparently only one ocean_proximity category is really useful, so you could try\n",
    "dropping the others).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3142707309668866, 'median_income'),\n",
       " (0.15464013000281696, 'INLAND'),\n",
       " (0.10829453494297761, 'pop_per_hhold'),\n",
       " (0.08046621515756835, 'longitude'),\n",
       " (0.0706684524806733, 'rooms_per_hhold'),\n",
       " (0.07012172021207927, 'bedrooms_per_room'),\n",
       " (0.0675178071507471, 'latitude'),\n",
       " (0.04285608669226521, 'housing_median_age'),\n",
       " (0.016853971185997182, 'population'),\n",
       " (0.016729018512079898, 'total_rooms'),\n",
       " (0.01621724612503511, '<1H OCEAN'),\n",
       " (0.015902697892088105, 'households'),\n",
       " (0.015823322284916393, 'total_bedrooms'),\n",
       " (0.00652680091396497, 'NEAR OCEAN'),\n",
       " (0.0030181200338671426, 'NEAR BAY'),\n",
       " (9.31454460368182e-05, 'ISLAND')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances_grid, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should also look at the specific errors that your system makes, then try to understand why it makes them and what could fix the problem (adding extra features or getting rid of uninformative ones, cleaning up outliers, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Your System on the Test Set\n",
    "\n",
    "Get the predictors and the labels from your test set, run your full_pipeline to transform the data (call transform(), not fit_transform() you do not want to fit the test set!), and evaluate the final model fit on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47415.84099297885"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the performance is worse than what you measured using cross-validation, you must resist the temptation to tweak the hyperparameters to make the numbers look good on the test set; the improvements would be unlikely to generalize to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Your Work\n",
    "You should save every model you experiment with so that you can come back easily to any model you want. Make sure you save both the hyperparameters and the trained parameters, as well as the\n",
    "cross-validation scores and perhaps the actual predictions as well. This will allow you to easily compare scores across model types, and compare the types of errors they make. You can easily save\n",
    "Scikit-Learn models by using Python’s module or by using pickle the library, which is more efficient at serializing large joblib NumPy arrays (you can install this library using pip):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(forest_scores, \"forest_scores.pkl\") #joblib.dump(my_model, \"my_model.pkl\")\n",
    "# and later...\n",
    "forest_scores_loaded = joblib.load(\"forest_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [49519.80364233 47461.9115823  50029.02762854 52325.28068953\n",
      " 49308.39426421 53446.37892622 48634.8036574  47585.73832311\n",
      " 53490.10699751 50021.5852922 ]\n",
      "Mean: 50182.303100336096\n",
      "Standard deviation: 2097.0810550985693\n"
     ]
    }
   ],
   "source": [
    "forest_rmse_scores_loaded = np.sqrt(-forest_scores_loaded)\n",
    "display_scores(forest_rmse_scores_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a Support Vector Machine regressor\n",
    "\n",
    "1. Try a Support Vector Machine regressor (sklearn.svm.SVR), with various hyperparameters such as kernel=\"linear\" (with various values for the C hyperparameter) or kernel=\"rbf\" (with various values for the C and gamma hyperparameters). Don't worry about what these hyperparameters mean for now. How does the best SVR predictor perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   9.3s\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   9.1s\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   9.1s\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   9.1s\n",
      "[CV] END ..............................C=10.0, kernel=linear; total time=   9.1s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   9.0s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   9.1s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time= 1.8min\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   9.0s\n",
      "[CV] END ..............................C=30.0, kernel=linear; total time=   9.0s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time= 1.1min\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=  38.4s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=   9.1s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=   8.9s\n",
      "[CV] END .............................C=100.0, kernel=linear; total time=   9.1s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   9.1s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   9.0s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   9.1s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   9.5s\n",
      "[CV] END .............................C=300.0, kernel=linear; total time=   9.0s\n",
      "[CV] END ............................C=1000.0, kernel=linear; total time=   9.1s\n",
      "[CV] END ............................C=1000.0, kernel=linear; total time=   9.1s\n",
      "[CV] END ............................C=1000.0, kernel=linear; total time=   9.2s\n",
      "[CV] END ............................C=1000.0, kernel=linear; total time=   9.2s\n",
      "[CV] END ............................C=1000.0, kernel=linear; total time=   9.2s\n",
      "[CV] END ............................C=3000.0, kernel=linear; total time=   9.9s\n",
      "[CV] END ............................C=3000.0, kernel=linear; total time=   9.3s\n",
      "[CV] END ............................C=3000.0, kernel=linear; total time=   9.4s\n",
      "[CV] END ............................C=3000.0, kernel=linear; total time=   9.4s\n",
      "[CV] END ............................C=3000.0, kernel=linear; total time=   9.6s\n",
      "[CV] END ...........................C=10000.0, kernel=linear; total time=  10.9s\n",
      "[CV] END ...........................C=10000.0, kernel=linear; total time=  10.5s\n",
      "[CV] END ...........................C=10000.0, kernel=linear; total time=  10.5s\n",
      "[CV] END ...........................C=10000.0, kernel=linear; total time=  10.5s\n",
      "[CV] END ...........................C=10000.0, kernel=linear; total time=  10.2s\n",
      "[CV] END ...........................C=30000.0, kernel=linear; total time=  13.5s\n",
      "[CV] END ...........................C=30000.0, kernel=linear; total time=  13.4s\n",
      "[CV] END ...........................C=30000.0, kernel=linear; total time=  13.8s\n",
      "[CV] END ...........................C=30000.0, kernel=linear; total time=  13.2s\n",
      "[CV] END ...........................C=30000.0, kernel=linear; total time=  12.7s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=1.0, gamma=0.01, kernel=rbf; total time=  17.7s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=1.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=  17.4s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=  17.5s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=  17.4s\n",
      "[CV] END .......................C=1.0, gamma=0.1, kernel=rbf; total time=  17.6s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=  17.3s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=  17.2s\n",
      "[CV] END .......................C=1.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=  16.8s\n",
      "[CV] END .......................C=1.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=  16.4s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=  16.3s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=  16.3s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=  16.3s\n",
      "[CV] END .......................C=1.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=3.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=  17.4s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=  17.6s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=3.0, gamma=0.03, kernel=rbf; total time=  17.4s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=  17.9s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=  17.6s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=  17.4s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=  17.4s\n",
      "[CV] END .......................C=3.0, gamma=0.1, kernel=rbf; total time=  17.4s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END .......................C=3.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=  16.9s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=  16.7s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .......................C=3.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=  16.3s\n",
      "[CV] END .......................C=3.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=  17.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=10.0, gamma=0.01, kernel=rbf; total time=  17.4s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=  17.4s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=  17.4s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=10.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END ......................C=10.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=  17.0s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=  17.2s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=  17.2s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END ......................C=10.0, gamma=0.3, kernel=rbf; total time=  17.0s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=10.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=  16.3s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ......................C=10.0, gamma=3.0, kernel=rbf; total time=  16.4s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.01, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END .....................C=30.0, gamma=0.03, kernel=rbf; total time=  17.5s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=  17.4s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=  17.4s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END ......................C=30.0, gamma=0.1, kernel=rbf; total time=  17.3s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=  17.0s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=  17.0s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=  17.1s\n",
      "[CV] END ......................C=30.0, gamma=0.3, kernel=rbf; total time=  17.0s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=30.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ......................C=30.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ....................C=100.0, gamma=0.01, kernel=rbf; total time=  17.4s\n",
      "[CV] END ....................C=100.0, gamma=0.01, kernel=rbf; total time=  17.4s\n",
      "[CV] END ....................C=100.0, gamma=0.01, kernel=rbf; total time=  17.4s\n",
      "[CV] END ....................C=100.0, gamma=0.01, kernel=rbf; total time=  17.4s\n",
      "[CV] END ....................C=100.0, gamma=0.01, kernel=rbf; total time=  17.4s\n",
      "[CV] END ....................C=100.0, gamma=0.03, kernel=rbf; total time=  17.2s\n",
      "[CV] END ....................C=100.0, gamma=0.03, kernel=rbf; total time=  17.2s\n",
      "[CV] END ....................C=100.0, gamma=0.03, kernel=rbf; total time=  17.3s\n",
      "[CV] END ....................C=100.0, gamma=0.03, kernel=rbf; total time=  17.4s\n",
      "[CV] END ....................C=100.0, gamma=0.03, kernel=rbf; total time=  17.3s\n",
      "[CV] END .....................C=100.0, gamma=0.1, kernel=rbf; total time=  17.0s\n",
      "[CV] END .....................C=100.0, gamma=0.1, kernel=rbf; total time=  17.0s\n",
      "[CV] END .....................C=100.0, gamma=0.1, kernel=rbf; total time=  17.0s\n",
      "[CV] END .....................C=100.0, gamma=0.1, kernel=rbf; total time=  17.0s\n",
      "[CV] END .....................C=100.0, gamma=0.1, kernel=rbf; total time=  17.0s\n",
      "[CV] END .....................C=100.0, gamma=0.3, kernel=rbf; total time=  16.8s\n",
      "[CV] END .....................C=100.0, gamma=0.3, kernel=rbf; total time=  16.9s\n",
      "[CV] END .....................C=100.0, gamma=0.3, kernel=rbf; total time=  16.8s\n",
      "[CV] END .....................C=100.0, gamma=0.3, kernel=rbf; total time=  16.8s\n",
      "[CV] END .....................C=100.0, gamma=0.3, kernel=rbf; total time=  16.8s\n",
      "[CV] END .....................C=100.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END .....................C=100.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END .....................C=100.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END .....................C=100.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .....................C=100.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END .....................C=100.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END .....................C=100.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END .....................C=100.0, gamma=3.0, kernel=rbf; total time=  16.3s\n",
      "[CV] END .....................C=100.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END .....................C=100.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ....................C=300.0, gamma=0.01, kernel=rbf; total time=  17.2s\n",
      "[CV] END ....................C=300.0, gamma=0.01, kernel=rbf; total time=  17.2s\n",
      "[CV] END ....................C=300.0, gamma=0.01, kernel=rbf; total time=  17.2s\n",
      "[CV] END ....................C=300.0, gamma=0.01, kernel=rbf; total time=  17.2s\n",
      "[CV] END ....................C=300.0, gamma=0.01, kernel=rbf; total time=  17.2s\n",
      "[CV] END ....................C=300.0, gamma=0.03, kernel=rbf; total time=  17.1s\n",
      "[CV] END ....................C=300.0, gamma=0.03, kernel=rbf; total time=  16.9s\n",
      "[CV] END ....................C=300.0, gamma=0.03, kernel=rbf; total time=  16.9s\n",
      "[CV] END ....................C=300.0, gamma=0.03, kernel=rbf; total time=  16.9s\n",
      "[CV] END ....................C=300.0, gamma=0.03, kernel=rbf; total time=  17.0s\n",
      "[CV] END .....................C=300.0, gamma=0.1, kernel=rbf; total time=  16.8s\n",
      "[CV] END .....................C=300.0, gamma=0.1, kernel=rbf; total time=  16.7s\n",
      "[CV] END .....................C=300.0, gamma=0.1, kernel=rbf; total time=  16.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .....................C=300.0, gamma=0.1, kernel=rbf; total time=  16.7s\n",
      "[CV] END .....................C=300.0, gamma=0.1, kernel=rbf; total time=  16.7s\n",
      "[CV] END .....................C=300.0, gamma=0.3, kernel=rbf; total time=  16.7s\n",
      "[CV] END .....................C=300.0, gamma=0.3, kernel=rbf; total time=  16.7s\n",
      "[CV] END .....................C=300.0, gamma=0.3, kernel=rbf; total time=  16.7s\n",
      "[CV] END .....................C=300.0, gamma=0.3, kernel=rbf; total time=  16.6s\n",
      "[CV] END .....................C=300.0, gamma=0.3, kernel=rbf; total time=  16.8s\n",
      "[CV] END .....................C=300.0, gamma=1.0, kernel=rbf; total time=  16.6s\n",
      "[CV] END .....................C=300.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END .....................C=300.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END .....................C=300.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END .....................C=300.0, gamma=1.0, kernel=rbf; total time=  16.5s\n",
      "[CV] END .....................C=300.0, gamma=3.0, kernel=rbf; total time=  16.1s\n",
      "[CV] END .....................C=300.0, gamma=3.0, kernel=rbf; total time=  16.1s\n",
      "[CV] END .....................C=300.0, gamma=3.0, kernel=rbf; total time=  16.1s\n",
      "[CV] END .....................C=300.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END .....................C=300.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ...................C=1000.0, gamma=0.01, kernel=rbf; total time=  16.8s\n",
      "[CV] END ...................C=1000.0, gamma=0.01, kernel=rbf; total time=  16.8s\n",
      "[CV] END ...................C=1000.0, gamma=0.01, kernel=rbf; total time=  16.8s\n",
      "[CV] END ...................C=1000.0, gamma=0.01, kernel=rbf; total time=  16.9s\n",
      "[CV] END ...................C=1000.0, gamma=0.01, kernel=rbf; total time=  16.8s\n",
      "[CV] END ...................C=1000.0, gamma=0.03, kernel=rbf; total time=  16.7s\n",
      "[CV] END ...................C=1000.0, gamma=0.03, kernel=rbf; total time=  16.7s\n",
      "[CV] END ...................C=1000.0, gamma=0.03, kernel=rbf; total time=  16.7s\n",
      "[CV] END ...................C=1000.0, gamma=0.03, kernel=rbf; total time=  16.7s\n",
      "[CV] END ...................C=1000.0, gamma=0.03, kernel=rbf; total time=  16.6s\n",
      "[CV] END ....................C=1000.0, gamma=0.1, kernel=rbf; total time=  16.5s\n",
      "[CV] END ....................C=1000.0, gamma=0.1, kernel=rbf; total time=  16.5s\n",
      "[CV] END ....................C=1000.0, gamma=0.1, kernel=rbf; total time=  16.6s\n",
      "[CV] END ....................C=1000.0, gamma=0.1, kernel=rbf; total time=  17.4s\n",
      "[CV] END ....................C=1000.0, gamma=0.1, kernel=rbf; total time=  16.6s\n",
      "[CV] END ....................C=1000.0, gamma=0.3, kernel=rbf; total time=  16.6s\n",
      "[CV] END ....................C=1000.0, gamma=0.3, kernel=rbf; total time=  16.5s\n",
      "[CV] END ....................C=1000.0, gamma=0.3, kernel=rbf; total time=  16.5s\n",
      "[CV] END ....................C=1000.0, gamma=0.3, kernel=rbf; total time=  16.6s\n",
      "[CV] END ....................C=1000.0, gamma=0.3, kernel=rbf; total time=  16.5s\n",
      "[CV] END ....................C=1000.0, gamma=1.0, kernel=rbf; total time=  16.4s\n",
      "[CV] END ....................C=1000.0, gamma=1.0, kernel=rbf; total time=  16.4s\n",
      "[CV] END ....................C=1000.0, gamma=1.0, kernel=rbf; total time=  16.4s\n",
      "[CV] END ....................C=1000.0, gamma=1.0, kernel=rbf; total time=  16.4s\n",
      "[CV] END ....................C=1000.0, gamma=1.0, kernel=rbf; total time=  16.4s\n",
      "[CV] END ....................C=1000.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ....................C=1000.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ....................C=1000.0, gamma=3.0, kernel=rbf; total time=  16.1s\n",
      "[CV] END ....................C=1000.0, gamma=3.0, kernel=rbf; total time=  16.2s\n",
      "[CV] END ....................C=1000.0, gamma=3.0, kernel=rbf; total time=  16.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVR(),\n",
       "             param_grid=[{'C': [10.0, 30.0, 100.0, 300.0, 1000.0, 3000.0,\n",
       "                                10000.0, 30000.0],\n",
       "                          'kernel': ['linear']},\n",
       "                         {'C': [1.0, 3.0, 10.0, 30.0, 100.0, 300.0, 1000.0],\n",
       "                          'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0],\n",
       "                          'kernel': ['rbf']}],\n",
       "             scoring='neg_mean_squared_error', verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "        {'kernel': ['linear'], 'C': [10., 30., 100., 300., 1000., 3000., 10000., 30000.0]},\n",
    "        {'kernel': ['rbf'], 'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "         'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]},\n",
    "    ]\n",
    "\n",
    "svm_reg = SVR()\n",
    "grid_search = GridSearchCV(svm_reg, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70363.84008695737"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_mse = grid_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 30000.0, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the value of C is the maximum tested value. When this happens you definitely want to launch the grid search again with higher values for C (removing the smallest values), because it is likely that higher values of C will be better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Try replacing GridSearchCV with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   8.9s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   9.0s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   9.0s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   9.0s\n",
      "[CV] END C=629.782329591372, gamma=3.010121430917521, kernel=linear; total time=   9.0s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  17.5s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  17.6s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  17.5s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  17.5s\n",
      "[CV] END C=26290.206464300216, gamma=0.9084469696321253, kernel=rbf; total time=  17.7s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  17.1s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  17.1s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  17.1s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  17.1s\n",
      "[CV] END C=84.14107900575871, gamma=0.059838768608680676, kernel=rbf; total time=  17.0s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   8.8s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   8.7s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   8.8s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   8.9s\n",
      "[CV] END C=432.37884813148855, gamma=0.15416196746656105, kernel=linear; total time=   9.0s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  16.2s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  16.3s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  16.4s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  16.4s\n",
      "[CV] END C=24.17508294611391, gamma=3.503557475158312, kernel=rbf; total time=  16.3s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  16.9s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  16.9s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  16.9s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  16.9s\n",
      "[CV] END C=113564.03940586245, gamma=0.0007790692366582295, kernel=rbf; total time=  16.9s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  17.0s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  17.0s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  17.0s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  17.0s\n",
      "[CV] END C=108.30488238805073, gamma=0.3627537294604771, kernel=rbf; total time=  17.1s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   9.1s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=  10.0s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   9.2s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   9.2s\n",
      "[CV] END C=21.344953672647435, gamma=0.023332523598323388, kernel=linear; total time=   9.2s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  16.8s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  16.8s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  16.8s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  16.7s\n",
      "[CV] END C=5603.270317432516, gamma=0.15023452872733867, kernel=rbf; total time=  16.3s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  23.2s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  24.6s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  26.4s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  23.8s\n",
      "[CV] END C=157055.10989448498, gamma=0.26497040005002437, kernel=rbf; total time=  25.4s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  13.8s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  13.5s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  13.7s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  13.2s\n",
      "[CV] END C=27652.464358739708, gamma=0.2227358621286903, kernel=linear; total time=  12.1s\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time= 4.7min\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time= 1.5min\n",
      "[CV] END C=171377.39570378003, gamma=0.628789100540856, kernel=linear; total time=15.4min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "# see https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "# for `expon()` and `reciprocal()` documentation and more probability distribution functions.\n",
    "\n",
    "# Note: gamma is ignored when kernel is \"linear\"\n",
    "param_distribs = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': reciprocal(20, 200000),\n",
    "        'gamma': expon(scale=1.0),\n",
    "    }\n",
    "\n",
    "svm_reg = SVR()\n",
    "rnd_search = RandomizedSearchCV(svm_reg, param_distributions=param_distribs,\n",
    "                                n_iter=50, cv=5, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mse = rnd_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the exponential distribution we used, with `scale=1.0`. Note that some samples are much larger or smaller than 1.0, but when you look at the log of the distribution, you can see that most values are actually concentrated roughly in the range of exp(-2) to exp(+2), which is about 0.1 to 7.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "expon_distrib = expon(scale=1.)\n",
    "samples = expon_distrib.rvs(10000, random_state=42)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Exponential distribution (scale=1.0)\")\n",
    "plt.hist(samples, bins=50)\n",
    "plt.subplot(122)\n",
    "plt.title(\"Log of this distribution\")\n",
    "plt.hist(np.log(samples), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution we used for `C` looks quite different: the scale of the samples is picked from a uniform distribution within a given range, which is why the right graph, which represents the log of the samples, looks roughly constant. This distribution is useful when you don't have a clue of what the target scale is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reciprocal_distrib = reciprocal(20, 200000)\n",
    "samples = reciprocal_distrib.rvs(10000, random_state=42)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Reciprocal distribution (scale=1.0)\")\n",
    "plt.hist(samples, bins=50)\n",
    "plt.subplot(122)\n",
    "plt.title(\"Log of this distribution\")\n",
    "plt.hist(np.log(samples), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reciprocal distribution is useful when you have no idea what the scale of the hyperparameter should be (indeed, as you can see on the figure on the right, all scales are equally likely, within the given range), whereas the exponential distribution is best when you know (more or less) what the scale of the hyperparameter should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try adding a transformer in the preparation pipeline to select only the most important attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def indices_of_top_k(arr, k):\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_importances, k):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this feature selector assumes that you have already computed the feature importances somehow (for example using a `RandomForestRegressor`). You may be tempted to compute them directly in the `TopFeatureSelector`'s `fit()` method, however this would likely slow down grid/randomized search since the feature importances would have to be computed for every hyperparameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = feature_importances_grid\n",
    "\n",
    "k = 5\n",
    "top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
    "top_k_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation_and_feature_selection_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared_top_k_features = preparation_and_feature_selection_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared_top_k_features[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared[0:3, top_k_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try creating a single pipeline that does the full data preparation plus the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_select_and_predict_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k)),\n",
    "    ('svm_reg', SVR(**rnd_search.best_params_))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_select_and_predict_pipeline.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = housing.iloc[:4]\n",
    "some_labels = housing_labels.iloc[:4]\n",
    "\n",
    "print(\"Predictions:\\t\", prepare_select_and_predict_pipeline.predict(some_data))\n",
    "print(\"Labels:\\t\\t\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically explore some preparation options using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "    'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    'feature_selection__k': list(range(1, len(feature_importances) + 1))\n",
    "}]\n",
    "\n",
    "grid_search_prep = GridSearchCV(prepare_select_and_predict_pipeline, param_grid, cv=5,\n",
    "                                scoring='neg_mean_squared_error', verbose=2)\n",
    "grid_search_prep.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_prep.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best imputer strategy is most_frequent and apparently almost all features are useful (15 out of 16). The last one (ISLAND) seems to just add some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
